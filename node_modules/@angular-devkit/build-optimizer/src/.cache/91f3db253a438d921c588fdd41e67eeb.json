{"remainingRequest":"/Users/vamsikarri/Desktop/Gathi/Angular/FederatedQuery/node_modules/@angular-devkit/build-optimizer/src/build-optimizer/webpack-loader.js??ref--3-1!/Users/vamsikarri/Desktop/Gathi/Angular/FederatedQuery/node_modules/plotly.js/src/traces/carpet/smooth_fill_2d_array.js","dependencies":[{"path":"/Users/vamsikarri/Desktop/Gathi/Angular/FederatedQuery/node_modules/plotly.js/src/traces/carpet/smooth_fill_2d_array.js","mtime":1529418310708},{"path":"/Users/vamsikarri/Desktop/Gathi/Angular/FederatedQuery/node_modules/cache-loader/dist/cjs.js","mtime":1529418306962},{"path":"/Users/vamsikarri/Desktop/Gathi/Angular/FederatedQuery/node_modules/@angular-devkit/build-optimizer/src/build-optimizer/webpack-loader.js","mtime":1529418304772}],"contextDependencies":[],"result":["/**\n* Copyright 2012-2018, Plotly, Inc.\n* All rights reserved.\n*\n* This source code is licensed under the MIT license found in the\n* LICENSE file in the root directory of this source tree.\n*/\n\n'use strict';\n\nvar Lib = require('../../lib');\n\n/*\n * Given a 2D array as well as a basis in either direction, this function fills in the\n * 2D array using a combination of smoothing and extrapolation. This is rather important\n * for carpet plots since it's used for layout so that we can't simply omit or blank out\n * points. We need a reasonable guess so that the interpolation puts points somewhere\n * even if we were to somehow represent that the data was missing later on.\n *\n * input:\n *  - data: 2D array of arrays\n *  - a: array such that a.length === data[0].length\n *  - b: array such that b.length === data.length\n */\nmodule.exports = function smoothFill2dArray(data, a, b) {\n    var i, j, k;\n    var ip = [];\n    var jp = [];\n    // var neighborCnts = [];\n\n    var ni = data[0].length;\n    var nj = data.length;\n\n    function avgSurrounding(i, j) {\n        // As a low-quality start, we can simply average surrounding points (in a not\n        // non-uniform grid aware manner):\n        var sum = 0.0;\n        var val;\n        var cnt = 0;\n        if(i > 0 && (val = data[j][i - 1]) !== undefined) {\n            cnt++;\n            sum += val;\n        }\n        if(i < ni - 1 && (val = data[j][i + 1]) !== undefined) {\n            cnt++;\n            sum += val;\n        }\n        if(j > 0 && (val = data[j - 1][i]) !== undefined) {\n            cnt++;\n            sum += val;\n        }\n        if(j < nj - 1 && (val = data[j + 1][i]) !== undefined) {\n            cnt++;\n            sum += val;\n        }\n        return sum / Math.max(1, cnt);\n\n    }\n\n    // This loop iterates over all cells. Any cells that are null will be noted and those\n    // are the only points we will loop over and update via laplace's equation. Points with\n    // any neighbors will receive the average. If there are no neighboring points, then they\n    // will be set to zero. Also as we go, track the maximum magnitude so that we can scale\n    // our tolerance accordingly.\n    var dmax = 0.0;\n    for(i = 0; i < ni; i++) {\n        for(j = 0; j < nj; j++) {\n            if(data[j][i] === undefined) {\n                ip.push(i);\n                jp.push(j);\n\n                data[j][i] = avgSurrounding(i, j);\n                // neighborCnts.push(result.neighbors);\n            }\n            dmax = Math.max(dmax, Math.abs(data[j][i]));\n        }\n    }\n\n    if(!ip.length) return data;\n\n    // The tolerance doesn't need to be excessive. It's just for display positioning\n    var dxp, dxm, dap, dam, dbp, dbm, c, d, diff, reldiff, overrelaxation;\n    var tol = 1e-5;\n    var resid = 0;\n    var itermax = 100;\n    var iter = 0;\n    var n = ip.length;\n    do {\n        resid = 0;\n        // Normally we'd loop in two dimensions, but not all points are blank and need\n        // an update, so we instead loop only over the points that were tabulated above\n        for(k = 0; k < n; k++) {\n            i = ip[k];\n            j = jp[k];\n            // neighborCnt = neighborCnts[k];\n\n            // Track a counter for how many contributions there are. We'll use this counter\n            // to average at the end, which reduces to laplace's equation with neumann boundary\n            // conditions on the first derivative (second derivative is zero so that we get\n            // a nice linear extrapolation at the boundaries).\n            var boundaryCnt = 0;\n            var newVal = 0;\n\n            var d0, d1, x0, x1, i0, j0;\n            if(i === 0) {\n                // If this lies along the i = 0 boundary, extrapolate from the two points\n                // to the right of this point. Note that the finite differences take into\n                // account non-uniform grid spacing:\n                i0 = Math.min(ni - 1, 2);\n                x0 = a[i0];\n                x1 = a[1];\n                d0 = data[j][i0];\n                d1 = data[j][1];\n                newVal += d1 + (d1 - d0) * (a[0] - x1) / (x1 - x0);\n                boundaryCnt++;\n            } else if(i === ni - 1) {\n                // If along the high i boundary, extrapolate from the two points to the\n                // left of this point\n                i0 = Math.max(0, ni - 3);\n                x0 = a[i0];\n                x1 = a[ni - 2];\n                d0 = data[j][i0];\n                d1 = data[j][ni - 2];\n                newVal += d1 + (d1 - d0) * (a[ni - 1] - x1) / (x1 - x0);\n                boundaryCnt++;\n            }\n\n            if((i === 0 || i === ni - 1) && (j > 0 && j < nj - 1)) {\n                // If along the min(i) or max(i) boundaries, also smooth vertically as long\n                // as we're not in a corner. Note that the finite differences used here\n                // are also aware of nonuniform grid spacing:\n                dxp = b[j + 1] - b[j];\n                dxm = b[j] - b[j - 1];\n                newVal += (dxm * data[j + 1][i] + dxp * data[j - 1][i]) / (dxm + dxp);\n                boundaryCnt++;\n            }\n\n            if(j === 0) {\n                // If along the j = 0 boundary, extrpolate this point from the two points\n                // above it\n                j0 = Math.min(nj - 1, 2);\n                x0 = b[j0];\n                x1 = b[1];\n                d0 = data[j0][i];\n                d1 = data[1][i];\n                newVal += d1 + (d1 - d0) * (b[0] - x1) / (x1 - x0);\n                boundaryCnt++;\n            } else if(j === nj - 1) {\n                // Same for the max j boundary from the cells below it:\n                j0 = Math.max(0, nj - 3);\n                x0 = b[j0];\n                x1 = b[nj - 2];\n                d0 = data[j0][i];\n                d1 = data[nj - 2][i];\n                newVal += d1 + (d1 - d0) * (b[nj - 1] - x1) / (x1 - x0);\n                boundaryCnt++;\n            }\n\n            if((j === 0 || j === nj - 1) && (i > 0 && i < ni - 1)) {\n                // Now average points to the left/right as long as not in a corner:\n                dxp = a[i + 1] - a[i];\n                dxm = a[i] - a[i - 1];\n                newVal += (dxm * data[j][i + 1] + dxp * data[j][i - 1]) / (dxm + dxp);\n                boundaryCnt++;\n            }\n\n            if(!boundaryCnt) {\n                // If none of the above conditions were triggered, then this is an interior\n                // point and we can just do a laplace equation update. As above, these differences\n                // are aware of nonuniform grid spacing:\n                dap = a[i + 1] - a[i];\n                dam = a[i] - a[i - 1];\n                dbp = b[j + 1] - b[j];\n                dbm = b[j] - b[j - 1];\n\n                // These are just some useful constants for the iteration, which is perfectly\n                // straightforward but a little long to derive from f_xx + f_yy = 0.\n                c = dap * dam * (dap + dam);\n                d = dbp * dbm * (dbp + dbm);\n\n                newVal = (c * (dbm * data[j + 1][i] + dbp * data[j - 1][i]) +\n                          d * (dam * data[j][i + 1] + dap * data[j][i - 1])) /\n                          (d * (dam + dap) + c * (dbm + dbp));\n            } else {\n                // If we did have contributions from the boundary conditions, then average\n                // the result from the various contributions:\n                newVal /= boundaryCnt;\n            }\n\n            // Jacobi updates are ridiculously slow to converge, so this approach uses a\n            // Gauss-seidel iteration which is dramatically faster.\n            diff = newVal - data[j][i];\n            reldiff = diff / dmax;\n            resid += reldiff * reldiff;\n\n            // Gauss-Seidel-ish iteration, omega chosen based on heuristics and some\n            // quick tests.\n            //\n            // NB: Don't overrelax the boundarie. Otherwise set an overrelaxation factor\n            // which is a little low but safely optimal-ish:\n            overrelaxation = boundaryCnt ? 0 : 0.85;\n\n            // If there are four non-null neighbors, then we want a simple average without\n            // overrelaxation. If all the surrouding points are null, then we want the full\n            // overrelaxation\n            //\n            // Based on experiments, this actually seems to slow down convergence just a bit.\n            // I'll leave it here for reference in case this needs to be revisited, but\n            // it seems to work just fine without this.\n            // if (overrelaxation) overrelaxation *= (4 - neighborCnt) / 4;\n\n            data[j][i] += diff * (1 + overrelaxation);\n        }\n\n        resid = Math.sqrt(resid);\n    } while(iter++ < itermax && resid > tol);\n\n    Lib.log('Smoother converged to', resid, 'after', iter, 'iterations');\n\n    return data;\n};\n",null]}